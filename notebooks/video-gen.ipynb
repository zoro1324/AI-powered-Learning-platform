{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Video Generation Pipeline\n",
                "\n",
                "This notebook generates a video from a given topic or text using Ollama for scripting, PIL for slides, Edge-TTS for audio, and MoviePy for assembly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import os\n",
                "import textwrap\n",
                "import requests\n",
                "import asyncio\n",
                "from PIL import Image, ImageDraw, ImageFont\n",
                "import edge_tts\n",
                "from moviepy.editor import ImageClip, AudioFileClip, concatenate_videoclips, VideoFileClip"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "OLLAMA_API_URL = \"http://localhost:11434/api/generate\"\n",
                "# Use 'llama3' or another model you have installed\n",
                "OLLAMA_MODEL = \"llama3\"\n",
                "\n",
                "OUTPUT_DIR = \"output\"\n",
                "SCENE_DIR = os.path.join(OUTPUT_DIR, \"scenes\")\n",
                "AUDIO_DIR = os.path.join(OUTPUT_DIR, \"audio\")\n",
                "FINAL_VIDEO_DIR = os.path.join(OUTPUT_DIR, \"video\")\n",
                "\n",
                "os.makedirs(SCENE_DIR, exist_ok=True)\n",
                "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
                "os.makedirs(FINAL_VIDEO_DIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Script Generation with Ollama"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "def generate_script(topic):\n",
                "    prompt = f\"\"\"\n",
                "    Convert this topic into a structured video plan.\n",
                "    Topic: {topic}\n",
                "    Return JSON only:\n",
                "    {{\n",
                "      \"scenes\": [\n",
                "        {{\n",
                "          \"title\": \"\",\n",
                "          \"bullets\": [],\n",
                "          \"narration\": \"\"\n",
                "        }}\n",
                "      ]\n",
                "    }}\n",
                "    \"\"\"\n",
                "    \n",
                "    print(f\"Generating script for: {topic}...\")\n",
                "    try:\n",
                "        response = requests.post(OLLAMA_API_URL, json={\n",
                "            \"model\": OLLAMA_MODEL,\n",
                "            \"prompt\": prompt,\n",
                "            \"format\": \"json\",\n",
                "            \"stream\": False\n",
                "        })\n",
                "        response.raise_for_status()\n",
                "        return json.loads(response.json()['response'])\n",
                "    except requests.exceptions.RequestException as e:\n",
                "        print(f\"Error connecting to Ollama: {e}\")\n",
                "        return None\n",
                "    except json.JSONDecodeError:\n",
                "        print(\"Error decoding JSON response from Ollama.\")\n",
                "        return None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Slide Generation (PIL)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_slide(scene, index):\n",
                "    width, height = 1280, 720\n",
                "    # White background (you can change to gradient code if desired)\n",
                "    img = Image.new('RGB', (width, height), color='white')\n",
                "    draw = ImageDraw.Draw(img)\n",
                "    \n",
                "    # Attempt to load a nice font, fallback to default\n",
                "    try:\n",
                "        # Windows usually has arial\n",
                "        title_font = ImageFont.truetype(\"arial.ttf\", 70)\n",
                "        text_font = ImageFont.truetype(\"arial.ttf\", 40)\n",
                "    except:\n",
                "        title_font = ImageFont.load_default()\n",
                "        text_font = ImageFont.load_default()\n",
                "        \n",
                "    # Draw Title\n",
                "    title_text = scene.get('title', f\"Scene {index}\")\n",
                "    draw.text((50, 50), title_text, fill='black', font=title_font)\n",
                "    \n",
                "    # Draw Bullets\n",
                "    y = 180\n",
                "    bullets = scene.get('bullets', [])\n",
                "    for bullet in bullets:\n",
                "        # Wrap text\n",
                "        lines = textwrap.wrap(bullet, width=50)\n",
                "        for line in lines:\n",
                "            draw.text((80, y), f\"â€¢ {line}\", fill='black', font=text_font)\n",
                "            y += 50\n",
                "            \n",
                "    # Save slide\n",
                "    filename = os.path.join(SCENE_DIR, f\"scene_{index}.png\")\n",
                "    img.save(filename)\n",
                "    return filename"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Audio Generation (Edge-TTS)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def generate_audio(text, index):\n",
                "    # Voices: en-US-ChristopherNeural, en-US-AriaNeural, etc.\n",
                "    voice = \"en-US-ChristopherNeural\"\n",
                "    output_file = os.path.join(AUDIO_DIR, f\"scene_{index}.mp3\")\n",
                "    \n",
                "    print(f\"Generating audio for scene {index}...\")\n",
                "    try:\n",
                "        communicate = edge_tts.Communicate(text, voice)\n",
                "        await communicate.save(output_file)\n",
                "        return output_file\n",
                "    except Exception as e:\n",
                "        print(f\"Error generating audio: {e}\")\n",
                "        return None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Video Assembly (MoviePy)\n",
                "Uses MoviePy to combine image and audio into a video clip."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_video_clip(image_path, audio_path, index):\n",
                "    output_path = os.path.join(FINAL_VIDEO_DIR, f\"scene_{index}.mp4\")\n",
                "    \n",
                "    print(f\"Creating video clip for scene {index} using MoviePy...\")\n",
                "    try:\n",
                "        # Load Audio\n",
                "        audio_clip = AudioFileClip(audio_path)\n",
                "        # Create Image Clip with duration of audio\n",
                "        video_clip = ImageClip(image_path).set_duration(audio_clip.duration)\n",
                "        # Set Audio\n",
                "        video_clip = video_clip.set_audio(audio_clip)\n",
                "        # Write File\n",
                "        video_clip.write_videofile(output_path, fps=24, codec='libx264', audio_codec='aac')\n",
                "        \n",
                "        return output_path\n",
                "    except Exception as e:\n",
                "        print(f\"MoviePy failed for scene {index}: {e}\")\n",
                "        return None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Merge All Scenes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "def merge_scenes(video_files):\n",
                "    output_filename = \"final_video.mp4\"\n",
                "    \n",
                "    print(\"Merging all scenes into final video...\")\n",
                "    try:\n",
                "        # Create VideoFileClip objects for each file\n",
                "        clips = [VideoFileClip(f) for f in video_files]\n",
                "        \n",
                "        final_clip = concatenate_videoclips(clips)\n",
                "        final_clip.write_videofile(output_filename, fps=24, codec='libx264', audio_codec='aac')\n",
                "        print(f\"Done! Output: {output_filename}\")\n",
                "        return output_filename\n",
                "    except Exception as e:\n",
                "        print(f\"Error merging scenes: {e}\")\n",
                "        return None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Execution Pipeline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "async def main(topic):\n",
                "    # 1. Generate Script\n",
                "    script_data = generate_script(topic)\n",
                "    if not script_data:\n",
                "        return\n",
                "    \n",
                "    # Save plan for reference\n",
                "    with open(\"video_plan.json\", \"w\") as f:\n",
                "        json.dump(script_data, f, indent=2)\n",
                "    \n",
                "    scenes = script_data.get('scenes', [])\n",
                "    video_clips = []\n",
                "    \n",
                "    for i, scene in enumerate(scenes, 1):\n",
                "        print(f\"Processing Scene {i}: {scene.get('title')}\")\n",
                "        \n",
                "        # 2. Tools -> Image\n",
                "        img_path = create_slide(scene, i)\n",
                "        \n",
                "        # 3. Narration -> Audio\n",
                "        narration = scene.get('narration', '')\n",
                "        if not narration:\n",
                "            print(f\"Warning: No narration for scene {i}\")\n",
                "            continue\n",
                "            \n",
                "        audio_path = await generate_audio(narration, i)\n",
                "        if not audio_path:\n",
                "            continue\n",
                "            \n",
                "        # 4. Combine -> Clip\n",
                "        clip_path = create_video_clip(img_path, audio_path, i)\n",
                "        if clip_path:\n",
                "            video_clips.append(clip_path)\n",
                "            \n",
                "    # 5. Merge\n",
                "    if video_clips:\n",
                "        merge_scenes(video_clips)\n",
                "    else:\n",
                "        print(\"No video clips were created.\")\n",
                "\n",
                "# Example Usage\n",
                "# await main(\"The history of the internet\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
