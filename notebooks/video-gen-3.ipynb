{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Generation Pipeline v3 â€” Hierarchical (Topic â†’ Chapters â†’ Scenes)\n",
    "\n",
    "**Architecture:**\n",
    "- **LLM Planner** (llama3:8b): Generates a chapter-level blueprint from the topic\n",
    "- **LLM Expander** (llama3:8b): Expands each chapter into detailed scenes with 2â€“3 image prompts\n",
    "- **Stable Diffusion v1-5 + LCM LoRA**: Generates 2â€“3 visuals per scene (fast, 10 steps)\n",
    "- **Edge-TTS**: Narration audio per scene\n",
    "- **MoviePy**: Renders individual scene clips (image + audio)\n",
    "- **FFmpeg**: Stream-copy merges clips â†’ chapters â†’ final video (no re-encode, fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Imports & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\navee\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Config ready.\n",
      "PyTorch: 2.5.1+cu121 | CUDA: True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import textwrap\n",
    "import requests\n",
    "import asyncio\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import edge_tts\n",
    "from moviepy import ImageClip, AudioFileClip\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, LCMScheduler\n",
    "\n",
    "# â”€â”€ LLM Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/generate\"\n",
    "OLLAMA_MODEL   = \"llama3:8b\"          # GPU-backed model\n",
    "\n",
    "# â”€â”€ Output Directories â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "OUTPUT_DIR   = os.path.abspath(\"output_v3\")  # absolute path avoids FFmpeg concat doubling\n",
    "CHAPTERS_DIR = os.path.join(OUTPUT_DIR, \"chapters\")\n",
    "FINAL_VIDEO  = os.path.join(OUTPUT_DIR, \"final_video.mp4\")\n",
    "\n",
    "os.makedirs(CHAPTERS_DIR, exist_ok=True)\n",
    "\n",
    "# â”€â”€ Slide Dimensions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SLIDE_W, SLIDE_H = 1280, 720\n",
    "\n",
    "print(\"âœ… Config ready.\")\n",
    "print(f\"PyTorch: {torch.__version__} | CUDA: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Stable Diffusion Init (SD v1-5 + LCM LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Stable Diffusion on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:07<00:00,  1.21s/it]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Stable Diffusion ready.\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"\n",
    "LORA_ID  = \"latent-consistency/lcm-lora-sdv1-5\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Loading Stable Diffusion on {device}...\")\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    safety_checker=None\n",
    ").to(device)\n",
    "\n",
    "# Memory optimisations\n",
    "pipe.enable_attention_slicing()\n",
    "pipe.enable_vae_slicing()\n",
    "if device == \"cuda\":\n",
    "    pipe.enable_model_cpu_offload()\n",
    "\n",
    "# LCM LoRA â€” fast inference (10 steps)\n",
    "pipe.load_lora_weights(LORA_ID)\n",
    "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "def generate_image_sd(prompt_text: str, output_path: str) -> str | None:\n",
    "    \"\"\"Generate a flat educational illustration using SD + LCM LoRA.\"\"\"\n",
    "    full_prompt = (\n",
    "        f\"simple flat illustration of {prompt_text}, \"\n",
    "        \"minimal design, clean white background, \"\n",
    "        \"educational graphic, vector style, no text\"\n",
    "    )\n",
    "    try:\n",
    "        image = pipe(\n",
    "            prompt=full_prompt,\n",
    "            num_inference_steps=10,\n",
    "            guidance_scale=1.5,\n",
    "            height=512,\n",
    "            width=512\n",
    "        ).images[0]\n",
    "        image.save(output_path)\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸  SD error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… Stable Diffusion ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: LLM Planner â€” Chapter Blueprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_blueprint(topic: str) -> dict | None:\n",
    "    \"\"\"\n",
    "    Single LLM call: converts a topic into a high-level chapter plan.\n",
    "    Returns: { \"title\": str, \"chapters\": [ { \"chapter_title\", \"chapter_summary\", \"key_themes\" } ] }\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a video script planner.\n",
    "Convert this topic into a structured chapter plan for an educational video.\n",
    "Topic: {topic}\n",
    "\n",
    "Return ONLY valid JSON (no markdown, no extra text):\n",
    "{{\n",
    "  \"title\": \"<overall video title>\",\n",
    "  \"chapters\": [\n",
    "    {{\n",
    "      \"chapter_title\": \"<chapter title>\",\n",
    "      \"chapter_summary\": \"<one sentence summary>\",\n",
    "      \"key_themes\": [\"theme1\", \"theme2\", \"theme3\"]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Generate 3 to 5 chapters. Return ONLY the JSON object.\"\"\"\n",
    "\n",
    "    print(f\"ğŸ“‹ Planning chapters for: {topic}...\")\n",
    "    try:\n",
    "        resp = requests.post(OLLAMA_API_URL, json={\n",
    "            \"model\": OLLAMA_MODEL,\n",
    "            \"prompt\": prompt,\n",
    "            \"format\": \"json\",\n",
    "            \"stream\": False\n",
    "        }, timeout=120)\n",
    "        resp.raise_for_status()\n",
    "        data = json.loads(resp.json()[\"response\"])\n",
    "        print(f\"  âœ… Blueprint ready: {len(data.get('chapters', []))} chapters\")\n",
    "        return data\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"  âŒ Ollama connection error: {e}\")\n",
    "        return None\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"  âŒ JSON parse error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: LLM Expander â€” Scene Details per Chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_chapter(chapter: dict) -> dict | None:\n",
    "    \"\"\"\n",
    "    Second LLM call: expands a chapter summary into 3â€“5 detailed scenes.\n",
    "    Each scene has 2 image_prompts for Stable Diffusion.\n",
    "    Returns: { \"scenes\": [ { \"title\", \"bullets\", \"narration\", \"image_prompts\": [] } ] }\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a video scriptwriter.\n",
    "Expand this chapter into detailed scenes for an educational video.\n",
    "\n",
    "Chapter Title: {chapter['chapter_title']}\n",
    "Chapter Summary: {chapter['chapter_summary']}\n",
    "Key Themes: {', '.join(chapter.get('key_themes', []))}\n",
    "\n",
    "Return ONLY valid JSON (no markdown, no extra text):\n",
    "{{\n",
    "  \"scenes\": [\n",
    "    {{\n",
    "      \"title\": \"<scene title>\",\n",
    "      \"bullets\": [\"<key point 1>\", \"<key point 2>\", \"<key point 3>\"],\n",
    "      \"narration\": \"<60-90 word spoken narration for this scene>\",\n",
    "      \"image_prompts\": [\n",
    "        \"<visual description 1 for illustration>\",\n",
    "        \"<visual description 2 for illustration>\"\n",
    "      ]\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Generate 3 to 5 scenes. Each scene must have exactly 2 image_prompts. Return ONLY the JSON object.\"\"\"\n",
    "\n",
    "    print(f\"  ğŸ“ Expanding: {chapter['chapter_title']}...\")\n",
    "    try:\n",
    "        resp = requests.post(OLLAMA_API_URL, json={\n",
    "            \"model\": OLLAMA_MODEL,\n",
    "            \"prompt\": prompt,\n",
    "            \"format\": \"json\",\n",
    "            \"stream\": False\n",
    "        }, timeout=180)\n",
    "        resp.raise_for_status()\n",
    "        data = json.loads(resp.json()[\"response\"])\n",
    "        print(f\"    âœ… {len(data.get('scenes', []))} scenes generated\")\n",
    "        return data\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"    âŒ Ollama error: {e}\")\n",
    "        return None\n",
    "    except (json.JSONDecodeError, KeyError) as e:\n",
    "        print(f\"    âŒ JSON error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Scene Visuals (2 SD images per scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scene_images(scene: dict, scenes_dir: str, ch_i: int, sc_i: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Generate 2 SD images for a scene. Returns list of valid image paths.\n",
    "    \"\"\"\n",
    "    image_prompts = scene.get(\"image_prompts\", [])\n",
    "    paths = []\n",
    "    for img_i, prompt in enumerate(image_prompts[:2]):  # cap at 2\n",
    "        out_path = os.path.join(scenes_dir, f\"ch{ch_i}_sc{sc_i}_img{img_i}.png\")\n",
    "        print(f\"    ğŸ¨ Generating image {img_i+1}/2: {prompt[:50]}...\")\n",
    "        result = generate_image_sd(prompt, out_path)\n",
    "        if result:\n",
    "            paths.append(result)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Slide Renderer (PIL) â€” Title + Bullets + 2 Tiled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slide(scene: dict, image_paths: list[str], scenes_dir: str, ch_i: int, sc_i: int) -> str:\n",
    "    \"\"\"\n",
    "    Renders a 1280x720 slide:\n",
    "      - Left half: title + bullet points\n",
    "      - Right half: up to 2 SD images stacked vertically\n",
    "    \"\"\"\n",
    "    img = Image.new(\"RGB\", (SLIDE_W, SLIDE_H), color=\"#F8F9FA\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # â”€â”€ Fonts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    try:\n",
    "        title_font = ImageFont.truetype(\"arial.ttf\", 52)\n",
    "        body_font  = ImageFont.truetype(\"arial.ttf\", 32)\n",
    "    except:\n",
    "        title_font = ImageFont.load_default()\n",
    "        body_font  = ImageFont.load_default()\n",
    "\n",
    "    margin       = 50\n",
    "    text_width   = 580  # left half\n",
    "    right_start  = 660  # right half x start\n",
    "    right_width  = SLIDE_W - right_start - margin\n",
    "\n",
    "    # â”€â”€ Draw blue left accent bar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    draw.rectangle([(margin - 10, 40), (margin - 4, SLIDE_H - 40)], fill=\"#4A90D9\")\n",
    "\n",
    "    # â”€â”€ Draw Title â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    title = scene.get(\"title\", f\"Scene {sc_i}\")\n",
    "    wrapped_title = textwrap.wrap(title, width=22)\n",
    "    ty = 60\n",
    "    for line in wrapped_title:\n",
    "        draw.text((margin, ty), line, fill=\"#1A1A2E\", font=title_font)\n",
    "        ty += 62\n",
    "\n",
    "    # â”€â”€ Draw Bullets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    y = ty + 20\n",
    "    for bullet in scene.get(\"bullets\", []):\n",
    "        for line in textwrap.wrap(bullet, width=32):\n",
    "            draw.text((margin + 20, y), f\"â€¢ {line}\", fill=\"#333333\", font=body_font)\n",
    "            y += 42\n",
    "        y += 8  # extra gap between bullets\n",
    "\n",
    "    # â”€â”€ Paste SD Images (right half, stacked) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if image_paths:\n",
    "        num_imgs = len(image_paths)\n",
    "        slot_h   = (SLIDE_H - 2 * margin) // num_imgs\n",
    "\n",
    "        for idx, img_path in enumerate(image_paths):\n",
    "            try:\n",
    "                sd_img = Image.open(img_path)\n",
    "                # Fit into slot while preserving aspect ratio\n",
    "                aspect   = sd_img.width / sd_img.height\n",
    "                fit_h    = min(slot_h - 20, 320)\n",
    "                fit_w    = int(fit_h * aspect)\n",
    "                if fit_w > right_width:\n",
    "                    fit_w = right_width\n",
    "                    fit_h = int(fit_w / aspect)\n",
    "                sd_img = sd_img.resize((fit_w, fit_h), Image.Resampling.LANCZOS)\n",
    "                # Centre horizontally in right zone\n",
    "                x_pos = right_start + (right_width - fit_w) // 2\n",
    "                y_pos = margin + idx * slot_h + (slot_h - fit_h) // 2\n",
    "                img.paste(sd_img, (x_pos, y_pos))\n",
    "            except Exception as e:\n",
    "                print(f\"    âš ï¸  Could not paste image {idx}: {e}\")\n",
    "\n",
    "    # â”€â”€ Save â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    slide_path = os.path.join(scenes_dir, f\"ch{ch_i}_sc{sc_i}_slide.png\")\n",
    "    img.save(slide_path)\n",
    "    return slide_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Audio Generation (Edge-TTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_audio(text: str, audio_dir: str, ch_i: int, sc_i: int) -> str | None:\n",
    "    \"\"\"\n",
    "    Converts narration text to speech using Edge-TTS.\n",
    "    Voice: en-US-ChristopherNeural (male, GPU-friendly quality)\n",
    "    \"\"\"\n",
    "    voice       = \"en-US-ChristopherNeural\"\n",
    "    output_file = os.path.join(audio_dir, f\"ch{ch_i}_sc{sc_i}.mp3\")\n",
    "    print(f\"    ğŸ”Š Generating audio for ch{ch_i} sc{sc_i}...\")\n",
    "    try:\n",
    "        communicate = edge_tts.Communicate(text, voice)\n",
    "        await communicate.save(output_file)\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ TTS error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Scene Clip Renderer (MoviePy â€” single clip only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_scene_clip(slide_path: str, audio_path: str, clips_dir: str, ch_i: int, sc_i: int) -> str | None:\n",
    "    \"\"\"\n",
    "    Combines slide image + audio into a scene MP4 clip.\n",
    "    Duration is driven by the audio length. 24 fps, H.264/AAC.\n",
    "    \"\"\"\n",
    "    output_path = os.path.join(clips_dir, f\"ch{ch_i}_sc{sc_i}.mp4\")\n",
    "    print(f\"    ğŸ¬ Rendering clip: ch{ch_i}_sc{sc_i}.mp4\")\n",
    "    try:\n",
    "        audio = AudioFileClip(audio_path)\n",
    "        clip  = ImageClip(slide_path).with_duration(audio.duration).with_audio(audio)\n",
    "        clip.write_videofile(\n",
    "            output_path,\n",
    "            fps=24,\n",
    "            codec=\"libx264\",\n",
    "            audio_codec=\"aac\",\n",
    "            logger=None       # suppress MoviePy progress bars\n",
    "        )\n",
    "        audio.close()\n",
    "        clip.close()\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ MoviePy error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 & 8: FFmpeg Merging (Chapter + Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffmpeg_concat(clip_paths: list[str], output_path: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Generic FFmpeg stream-copy concatenator.\n",
    "    Writes a concat list file then calls ffmpeg -f concat -safe 0 -i list -c copy output.\n",
    "    Stream-copy = no re-encode â†’ extremely fast and supports arbitrarily long videos.\n",
    "    \"\"\"\n",
    "    if not clip_paths:\n",
    "        print(\"  âš ï¸  No clips to merge.\")\n",
    "        return None\n",
    "\n",
    "    list_file = output_path.replace(\".mp4\", \"_list.txt\")\n",
    "    with open(list_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for path in clip_paths:\n",
    "            # FFmpeg concat list requires forward slashes\n",
    "            abs_path = os.path.abspath(path).replace(chr(92), '/')\n",
    "            f.write(f\"file '{abs_path}'\\n\")\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\", \"-y\",\n",
    "        \"-f\", \"concat\",\n",
    "        \"-safe\", \"0\",\n",
    "        \"-i\", list_file,\n",
    "        \"-c\", \"copy\",\n",
    "        output_path\n",
    "    ]\n",
    "    print(f\"  ğŸ”— FFmpeg merging {len(clip_paths)} clips â†’ {os.path.basename(output_path)}\")\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"  âŒ FFmpeg error:\\n{result.stderr[-500:]}\")\n",
    "        return None\n",
    "    print(f\"  âœ… Merged: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def merge_chapter(ch_i: int, clip_paths: list[str], chapter_dir: str) -> str | None:\n",
    "    \"\"\"Step 7: Merge all scene clips of a chapter into chapter_i.mp4\"\"\"\n",
    "    out = os.path.join(chapter_dir, f\"chapter_{ch_i}.mp4\")\n",
    "    return ffmpeg_concat(clip_paths, out)\n",
    "\n",
    "\n",
    "def merge_final(chapter_paths: list[str]) -> str | None:\n",
    "    \"\"\"Step 8: Merge all chapter videos into final_video.mp4\"\"\"\n",
    "    return ffmpeg_concat(chapter_paths, FINAL_VIDEO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution Pipeline â€” `main(topic)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(topic: str):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸš€ Starting Video Generation: '{topic}'\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "    # â”€â”€ Step 1: Blueprint â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    blueprint = generate_blueprint(topic)\n",
    "    if not blueprint:\n",
    "        print(\"âŒ Blueprint generation failed. Aborting.\")\n",
    "        return\n",
    "\n",
    "    # Save blueprint for reference\n",
    "    blueprint_path = os.path.join(OUTPUT_DIR, \"video_blueprint.json\")\n",
    "    with open(blueprint_path, \"w\") as f:\n",
    "        json.dump(blueprint, f, indent=2)\n",
    "    print(f\"ğŸ“„ Blueprint saved â†’ {blueprint_path}\\n\")\n",
    "\n",
    "    chapters       = blueprint.get(\"chapters\", [])\n",
    "    chapter_videos = []   # final chapter MP4 paths\n",
    "\n",
    "    for ch_i, chapter in enumerate(chapters, start=1):\n",
    "        ch_title = chapter.get(\"chapter_title\", f\"Chapter {ch_i}\")\n",
    "        print(f\"\\n{'â”€'*50}\")\n",
    "        print(f\"ğŸ“– Chapter {ch_i}: {ch_title}\")\n",
    "        print(f\"{'â”€'*50}\")\n",
    "\n",
    "        # â”€â”€ Per-chapter directories â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        ch_dir     = os.path.join(CHAPTERS_DIR, f\"ch_{ch_i}\")\n",
    "        scenes_dir = os.path.join(ch_dir, \"scenes\")\n",
    "        audio_dir  = os.path.join(ch_dir, \"audio\")\n",
    "        clips_dir  = os.path.join(ch_dir, \"clips\")\n",
    "        for d in [scenes_dir, audio_dir, clips_dir]:\n",
    "            os.makedirs(d, exist_ok=True)\n",
    "\n",
    "        # â”€â”€ Step 2: Expand chapter â†’ scenes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        expansion = expand_chapter(chapter)\n",
    "        if not expansion:\n",
    "            print(f\"  âš ï¸  Skipping chapter {ch_i} â€” expansion failed.\")\n",
    "            continue\n",
    "\n",
    "        scenes      = expansion.get(\"scenes\", [])\n",
    "        scene_clips = []   # scene MP4 paths for this chapter\n",
    "\n",
    "        for sc_i, scene in enumerate(scenes, start=1):\n",
    "            sc_title = scene.get(\"title\", f\"Scene {sc_i}\")\n",
    "            print(f\"\\n  ğŸ¥ Scene {sc_i}/{len(scenes)}: {sc_title}\")\n",
    "\n",
    "            # â”€â”€ Step 3: Generate 2 SD visuals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            image_paths = generate_scene_images(scene, scenes_dir, ch_i, sc_i)\n",
    "\n",
    "            # â”€â”€ Step 4: Render slide â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            slide_path = create_slide(scene, image_paths, scenes_dir, ch_i, sc_i)\n",
    "\n",
    "            # â”€â”€ Step 5: Generate narration audio â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            narration = scene.get(\"narration\", \"\").strip()\n",
    "            if not narration:\n",
    "                print(f\"    âš ï¸  No narration for sc{sc_i} â€” skipping.\")\n",
    "                continue\n",
    "\n",
    "            audio_path = await generate_audio(narration, audio_dir, ch_i, sc_i)\n",
    "            if not audio_path:\n",
    "                continue\n",
    "\n",
    "            # â”€â”€ Step 6: Render scene clip â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "            clip_path = render_scene_clip(slide_path, audio_path, clips_dir, ch_i, sc_i)\n",
    "            if clip_path:\n",
    "                scene_clips.append(clip_path)\n",
    "\n",
    "        # â”€â”€ Step 7: FFmpeg merge â†’ chapter video â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        if scene_clips:\n",
    "            print(f\"\\n  â–º Merging {len(scene_clips)} scene clips for chapter {ch_i}...\")\n",
    "            ch_video = merge_chapter(ch_i, scene_clips, ch_dir)\n",
    "            if ch_video:\n",
    "                chapter_videos.append(ch_video)\n",
    "        else:\n",
    "            print(f\"  âš ï¸  No clips for chapter {ch_i}.\")\n",
    "\n",
    "    # â”€â”€ Step 8: FFmpeg merge â†’ final video â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    if chapter_videos:\n",
    "        print(f\"ğŸï¸  Merging {len(chapter_videos)} chapters into final video...\")\n",
    "        final = merge_final(chapter_videos)\n",
    "        if final:\n",
    "            print(f\"\\nğŸ‰ Done! Final video â†’ {final}\")\n",
    "    else:\n",
    "        print(\"âŒ No chapter videos created â€” nothing to merge.\")\n",
    "    print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â–¶ï¸ Run â€” Change the topic below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ğŸš€ Starting Video Generation: 'The history of Chess'\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ Planning chapters for: The history of Chess...\n",
      "  âœ… Blueprint ready: 4 chapters\n",
      "ğŸ“„ Blueprint saved â†’ d:\\AI-powered-Learning-platform\\notebooks\\output_v3\\video_blueprint.json\n",
      "\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“– Chapter 1: Ancient Origins and Early Development\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ğŸ“ Expanding: Ancient Origins and Early Development...\n",
      "    âœ… 4 scenes generated\n",
      "\n",
      "  ğŸ¥ Scene 1/4: The Birthplace of Chess\n",
      "    ğŸ¨ Generating image 1/2: An illustration of ancient Indian cities like Vara...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:09<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: A depiction of Indian soldiers playing chess durin...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch1 sc1...\n",
      "    ğŸ¬ Rendering clip: ch1_sc1.mp4\n",
      "\n",
      "  ğŸ¥ Scene 2/4: Chess in Ancient Persia\n",
      "    ğŸ¨ Generating image 1/2: A scene of camel caravans crossing the desert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: An illustration of a Persian palace with chess pla...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch1 sc2...\n",
      "    ğŸ¬ Rendering clip: ch1_sc2.mp4\n",
      "\n",
      "  ğŸ¥ Scene 3/4: The Rise of Chess in Asia\n",
      "    ğŸ¨ Generating image 1/2: A scene of Japanese samurai playing chess...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: An illustration of Korean royal courtiers engaged ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch1 sc3...\n",
      "    ğŸ¬ Rendering clip: ch1_sc3.mp4\n",
      "\n",
      "  ğŸ¥ Scene 4/4: Early Chess Variations\n",
      "    ğŸ¨ Generating image 1/2: An illustration of a Chinese board with different ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: A scene of Persian merchants playing Shatranj...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch1 sc4...\n",
      "    ğŸ¬ Rendering clip: ch1_sc4.mp4\n",
      "\n",
      "  â–º Merging 4 scene clips for chapter 1...\n",
      "  ğŸ”— FFmpeg merging 4 clips â†’ chapter_1.mp4\n",
      "  âœ… Merged: d:\\AI-powered-Learning-platform\\notebooks\\output_v3\\chapters\\ch_1\\chapter_1.mp4\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“– Chapter 2: The Middle Ages and European Influence\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ğŸ“ Expanding: The Middle Ages and European Influence...\n",
      "    âœ… 3 scenes generated\n",
      "\n",
      "  ğŸ¥ Scene 1/3: Scene 1: The Spread of Chess\n",
      "    ğŸ¨ Generating image 1/2: Sailors and merchants navigating medieval trade ro...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: A lavish illustration of a noble playing chess in ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch2 sc1...\n",
      "    ğŸ¬ Rendering clip: ch2_sc1.mp4\n",
      "\n",
      "  ğŸ¥ Scene 2/3: Scene 2: Chess in the Royal Court\n",
      "    ğŸ¨ Generating image 1/2: A regal illustration of King Arthur playing chess ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: A detailed depiction of a medieval chessboard in a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch2 sc2...\n",
      "    ğŸ¬ Rendering clip: ch2_sc2.mp4\n",
      "\n",
      "  ğŸ¥ Scene 3/3: Scene 3: The Rise of Written Records\n",
      "    ğŸ¨ Generating image 1/2: A medieval scribe writing a chess manual...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: A page from an ancient manuscript featuring a ches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch2 sc3...\n",
      "    ğŸ¬ Rendering clip: ch2_sc3.mp4\n",
      "\n",
      "  â–º Merging 3 scene clips for chapter 2...\n",
      "  ğŸ”— FFmpeg merging 3 clips â†’ chapter_2.mp4\n",
      "  âœ… Merged: d:\\AI-powered-Learning-platform\\notebooks\\output_v3\\chapters\\ch_2\\chapter_2.mp4\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“– Chapter 3: The Renaissance and Modern Era\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ğŸ“ Expanding: The Renaissance and Modern Era...\n",
      "    âœ… 3 scenes generated\n",
      "\n",
      "  ğŸ¥ Scene 1/3: The Renaissance Revival\n",
      "    ğŸ¨ Generating image 1/2: A illustration of Leonardo da Vinci playing chess ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: A depiction of a Renaissance-era chessboard with i...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch3 sc1...\n",
      "    ğŸ¬ Rendering clip: ch3_sc1.mp4\n",
      "\n",
      "  ğŸ¥ Scene 2/3: Emergence of Modern Tournaments\n",
      "    ğŸ¨ Generating image 1/2: A illustration of the 1851 London Chess Tournament...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: A depiction of a chess club meeting in the late 19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch3 sc2...\n",
      "    ğŸ¬ Rendering clip: ch3_sc2.mp4\n",
      "\n",
      "  ğŸ¥ Scene 3/3: Modern Era: Tournaments and Clubs Abound\n",
      "    ğŸ¨ Generating image 1/2: A depiction of a modern chess tournament with play...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: A screenshot of an online chess platform featuring...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch3 sc3...\n",
      "    ğŸ¬ Rendering clip: ch3_sc3.mp4\n",
      "\n",
      "  â–º Merging 3 scene clips for chapter 3...\n",
      "  ğŸ”— FFmpeg merging 3 clips â†’ chapter_3.mp4\n",
      "  âœ… Merged: d:\\AI-powered-Learning-platform\\notebooks\\output_v3\\chapters\\ch_3\\chapter_3.mp4\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "ğŸ“– Chapter 4: Chess Around the World\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  ğŸ“ Expanding: Chess Around the World...\n",
      "    âœ… 4 scenes generated\n",
      "\n",
      "  ğŸ¥ Scene 1/4: African Roots\n",
      "    ğŸ¨ Generating image 1/2: A illustration of an African chess set with unique...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:07<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: A scene showing children playing chess on a makesh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch4 sc1...\n",
      "    ğŸ¬ Rendering clip: ch4_sc1.mp4\n",
      "\n",
      "  ğŸ¥ Scene 2/4: Asian Flavors\n",
      "    ğŸ¨ Generating image 1/2: A illustration of a Japanese Shogi board and piece...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: A scene showing players gathered around a Xiangqi ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch4 sc2...\n",
      "    ğŸ¬ Rendering clip: ch4_sc2.mp4\n",
      "\n",
      "  ğŸ¥ Scene 3/4: Latin American Spirit\n",
      "    ğŸ¨ Generating image 1/2: A illustration of a Cuban chess set with a tambor ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: A scene showing children playing chess in a Brazil...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch4 sc3...\n",
      "    ğŸ¬ Rendering clip: ch4_sc3.mp4\n",
      "\n",
      "  ğŸ¥ Scene 4/4: Global Connectivity\n",
      "    ğŸ¨ Generating image 1/2: A illustration of a global chess network with conn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ¨ Generating image 2/2: A scene showing a online chess tournament in progr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ğŸ”Š Generating audio for ch4 sc4...\n",
      "    ğŸ¬ Rendering clip: ch4_sc4.mp4\n",
      "\n",
      "  â–º Merging 4 scene clips for chapter 4...\n",
      "  ğŸ”— FFmpeg merging 4 clips â†’ chapter_4.mp4\n",
      "  âœ… Merged: d:\\AI-powered-Learning-platform\\notebooks\\output_v3\\chapters\\ch_4\\chapter_4.mp4\n",
      "\n",
      "============================================================\n",
      "ğŸï¸  Merging 4 chapters into final video...\n",
      "  ğŸ”— FFmpeg merging 4 clips â†’ final_video.mp4\n",
      "  âœ… Merged: d:\\AI-powered-Learning-platform\\notebooks\\output_v3\\final_video.mp4\n",
      "\n",
      "ğŸ‰ Done! Final video â†’ d:\\AI-powered-Learning-platform\\notebooks\\output_v3\\final_video.mp4\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await main(\"The history of Chess\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
